{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccf4b1c-8e01-4edf-9c31-8d0917dbe2a4",
   "metadata": {},
   "source": [
    "# RNNs\n",
    "\n",
    "Before we start taking a look at the inner mechanics of recurrent neural networks (RNNs) we will take a look at our data and see where apporaches like CNN or Autoencoders lag and why we therefore introduce yet another type.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "It is worth comparing the entities of digital data.\n",
    "For this example we want to compare text and image data.\n",
    "\n",
    "Image | Text | Note\n",
    "--- | --- | ---\n",
    "Continous values: Colors expressed via RGB are continous, we can morph from green to blue | The meaning of car and bicycle are not continous but discrete | This is important for our loss function which helps our neural net to move into the proper direction via gradients. \n",
    "Two dimensional data (plus color) - we can often mirror the image w/o loosing semantics | Single dimension in *time* - the sequence of words is really important | The *temporal* dependency of text is vastly important - this can also lead way back into the past, e.g. the name of a protagonist of a story\n",
    "A single pixel rarely changes the whole semantics of a picture | Changing a single word (e.g. negation) can vastly change the meaning of a sentence | Our neural network needs to be robust and needs to avoid producing noise\n",
    "The structure of the data is given by the contrast of an image | The structure of a sentence is also given by its grammar which often relies on abstract notions such as past and future | \n",
    "A digital image has a fixed image size | The length of a text or sentence is not fixed and depends on its content |\n",
    "\n",
    "Although both kind of data are represented by bytes their formal structure differ a lot and therefore we need a new way to tackle data that has not a fixed size, like a text or a musical composition.\n",
    "\n",
    "Representing semeantics of text is a very tedious and complex task in computer science whose research is called [natural language processing (NLP)](https://en.wikipedia.org/wiki/Computational_linguistics).\n",
    "Neural networks also accelerated the progression in this domain and are used for translation of languages or sentiment analysis (is the text written in a positive or negative tone).\n",
    "\n",
    "To tackle this stream of text data we will use recurrent neural networks (RNNs) which have a feedback loop inside itself which allows for recursive calls on data and hencefore for a variable length of input and output.\n",
    "\n",
    "![RNN](rnn.svg)\n",
    "\n",
    "We often also illustrtate the layers in a more verbose, *unrolled* way.\n",
    "In this example our input data $X$ is arranged in such a way that for each 5 samples in a row and the RNN will output a single sample.\n",
    "Think of this as we show the RNN 5 words and want to know which one should be the next one.\n",
    "\n",
    "![RNN unrolled](rnn-unrolled.svg)\n",
    "\n",
    "There are different architectures of how this feedback loop is achived, one of the most used ones is [ Long short-term memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory) which we will also use in this notebook.\n",
    "\n",
    "As training data we will use *Der Proceß* by Franz Kafka which is available in txt format at [wikisource](https://de.wikisource.org/wiki/Der_Prozess)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46404c-1974-41d1-88e2-d9859f896f19",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "As always we need to talk about the pre-processing of our data.\n",
    "We want to train the RNN to write some Kafka-like texts but neural networks rely on mathematical notations and deviations which do not work on texts directly.\n",
    "Therefore we need to make a transition of words to numbers and there are 2 trivial approaches for this:\n",
    "\n",
    "* Word tokenization: Each word is assigned a token (number) is henceforth representated by this token\n",
    "* Character tokenization: Same as word tokenization but instead of words it uses chars\n",
    "\n",
    "This allows us to transform the text into a line of numbers (vector) on which we can work on as before.\n",
    "\n",
    "Both ways have advantages and disadvantages and we will try out both ways, although *Der Proceß* is not a really long book which may be not enough for \n",
    "Also is there a problem that german language conjugates words and makes it more difficult for the neural network to train on these as the token is different or we have to add a lot of work beforehand so our tokenization works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c34ea-5b89-4905-b594-0b3fca30d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ac2af",
   "metadata": {},
   "source": [
    "Lets start by taking a look at the text file if e.g. the encoding is properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b35e4-9685-4d7d-b261-9bf9d146c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Prozess\n",
      "\n",
      "\n",
      "\t\t\t\t\tFranz Kafka\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Die Schmiede, Berlin, 1925\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Exportiert aus Wikisource am 29. November 2021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[I] FRANZ KAFKA\n",
      "\n",
      "\n",
      "\n",
      "* * *\n",
      "\n",
      "\n",
      "\n",
      "Der Prozess\n",
      "\n",
      "ROMAN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VERLAG DIE SCHMIEDE\n",
      "\n",
      "BERLIN\n",
      "\n",
      "1925\n",
      "\n",
      "[II] EINBANDENTWURF GEORG SALTER · BERLIN\n",
      "\n",
      "COPYRIGHT 1925 BY VERLAG DIE SCHMIEDE · BERLIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Inhalt\n",
      "\n",
      "\n",
      "Erstes Kapitel\n",
      "\n",
      "Zweites Kapitel\n",
      "\n",
      "Drittes Kapitel\n",
      "\n",
      "Viertes Kapitel\n",
      "\n",
      "Fünftes Kapitel\n",
      "\n",
      "Sechstes Kapitel\n",
      "\n",
      "Siebentes Kapitel\n",
      "\n",
      "Achtes Kapitel\n",
      "\n",
      "Neuntes Kapitel\n",
      "\n",
      "Zehntes Kapitel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sekundärliteratur\n",
      "\n",
      "\n",
      "Kurt Tucholsky: Der Prozeß. In. Die Weltbühne. Jahrgang 22, Nummer 10, Seite 383–386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1] ERSTES KAPITEL\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VERHAFTUNG · GESPRÄCH MIT FRAU GRUBACH · DANN FRÄULEIN BÜRSTNER\n",
      "\n",
      "\n",
      "\n",
      "Jemand mußte Josef K. verleumdet haben, denn ohne daß er etwas Böses getan hätte, wurde er eines Morgens verhaftet. Die Köchin der Frau Grubach, seiner Zimmervermieterin, die ihm jeden Tag gegen acht Uhr früh das Frühstück brachte, kam diesmal nicht. Das war noch niemals geschehen. K. wartete noch ein Weilchen, \n"
     ]
    }
   ],
   "source": [
    "text_file_path = \"./Der_Prozess.txt\"\n",
    "\n",
    "with open(text_file_path, 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6892ad8-5155-474f-8689-2a1f1f15fea6",
   "metadata": {},
   "source": [
    "We will not get into too much of pre-processing here but will mention [regular expressions](https://en.wikipedia.org/wiki/Regular_expression) are a really great tool to verify or sanitize textstructures.\n",
    "\n",
    "We only want to perform a small analysis on the text what the most used words are - to split these properly we will use regular expressions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc5cc7-a6c8-46a3-8a4b-4096a616a509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 most used words in Proceß\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "der      1685\n",
       "und      1606\n",
       "die      1557\n",
       "er       1393\n",
       "zu       1052\n",
       "nicht     980\n",
       "den       853\n",
       "K.        850\n",
       "sich      839\n",
       "es        797\n",
       "in        756\n",
       "das       650\n",
       "sagte     643\n",
       "ich       640\n",
       "sie       578\n",
       "aber      575\n",
       "Sie       564\n",
       "daß       553\n",
       "mit       544\n",
       "dem       512\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"20 most used words in Proceß\")\n",
    "pd.Series(re.sub(r\"s{2,}\", \" \", text).replace(\"\\n\", \" \").replace(\"\\t\", \" \").split(\" \")).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = text.lower()\n",
    "text = text.replace('\\n', ' ')\n",
    "text = re.sub('  +', '. ', text).strip()\n",
    "text = text.replace('..', '.')\n",
    "\n",
    "text = re.sub('([!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~])', r' \\1 ', text)\n",
    "text = re.sub('\\s{2,}', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d306936-e7ce-4919-8faf-e18c91a4af9b",
   "metadata": {},
   "source": [
    "### Create tokens\n",
    "\n",
    "For now we will start with the char level approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792d11c-57d7-494f-9139-c359f1edbc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found chars: 92\n"
     ]
    }
   ],
   "source": [
    "char_tokenizer = Tokenizer(lower=False, filters='', char_level=True)\n",
    "char_tokenizer.fit_on_texts([text])\n",
    "num_chars = len(char_tokenizer.word_index)+1\n",
    "print(f\"Number of found chars: {num_chars}\")\n",
    "char_token_list = char_tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a7b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469649"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9d6e0-55cf-4af7-b3d6-98a0ffda508b",
   "metadata": {},
   "source": [
    "We will now need to transform this list of tokens into two vectors $X, y$ where $X$  is a series of $n$ tokens and $y$ is the vector with the perceeding tokens for these $n$ tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461de91-3e1e-4276-8f35-2a17fd359d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def generate_sequences(token_list: List[int], step: int, seq_length: int, num_classes: int):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(0, len(token_list) - seq_length, step):\n",
    "        X.append(token_list[i:i+seq_length])\n",
    "        y.append(token_list[i+seq_length])\n",
    "    \n",
    "    y = to_categorical(y, num_classes=num_classes)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2a5cc-fae9-4e05-88d9-9522ed73784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (469609, 40) \ty:  (469609, 92)\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_sequences(char_token_list, step=1, seq_length=40, num_classes=num_chars)\n",
    "\n",
    "print(\"X: \", X.shape, \"\\ty: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18890fd0",
   "metadata": {},
   "source": [
    "Note that $y$ does not output just a single number but the number of tokens that are available which is called [one hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "This has the advantage that we get the probability of each token instead of just the next token so it allows us to not always take the most probable next token but to deviate from it.\n",
    "\n",
    "We can take a look at the first sample from $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879ebdf-4380-47d9-841a-34544b0683bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38,  2,  5,  1, 48,  5, 17, 22,  2,  7,  7,  1, 21,  1, 40,  5,  8,\n",
       "        3, 22,  1, 29,  8, 20, 23,  8,  1, 21,  1, 38,  4,  2,  1, 28, 11,\n",
       "        9, 15,  4,  2, 10,  2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d070539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676622d6-44ae-47c6-8622-9704b98a6301",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building the LSTM network\n",
    "\n",
    "Now we can start building the network.\n",
    "Before we feed the tokens into the LSTM cell we will use an embedding.\n",
    "This allows the network to self-interpret the meaning of each token in its own learnable space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79b296-c6c4-47aa-8d5f-671fce76ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"char_rnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, None, 100)         9200      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               365568    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 92)                23644     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 398,412\n",
      "Trainable params: 398,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizer_v2.rmsprop import RMSprop\n",
    "\n",
    "n_units = 256\n",
    "embedding_size = 100\n",
    "\n",
    "text_in = layers.Input(shape=(None,))\n",
    "x = layers.Embedding(num_chars, embedding_size,)(text_in)\n",
    "x = layers.LSTM(n_units)(x)\n",
    "# x = layers.Dropout(0.2)(x)\n",
    "text_out = layers.Dense(num_chars, activation='softmax')(x)\n",
    "\n",
    "char_model = Model(text_in, text_out, name=\"char_rnn\")\n",
    "\n",
    "char_model.compile(\n",
    "    # note that we use the same loss as with MNIST\n",
    "    # which is used when we want to learn a\n",
    "    # probability distribution\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=RMSprop(learning_rate=0.001)\n",
    ")\n",
    "\n",
    "char_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1196d-44fc-4471-92a2-705e0e843743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14676/14676 [==============================] - 664s 45ms/step - loss: 1.6095\n",
      "Epoch 2/5\n",
      "14676/14676 [==============================] - 683s 47ms/step - loss: 1.2981\n",
      "Epoch 3/5\n",
      "14676/14676 [==============================] - 652s 44ms/step - loss: 1.2408\n",
      "Epoch 4/5\n",
      " 2518/14676 [====>.........................] - ETA: 9:28 - loss: 1.2010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v0/7q67mljd4v9_frk_1p_mr2ph0000gn/T/ipykernel_56345/2343676268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/musikinformatik_sose2021/venv/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0mare\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0mto\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRemoteValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "char_model.fit(X, y, epochs=5, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467e09d",
   "metadata": {},
   "source": [
    "Now we can write a function which continues to write a text on a given input.\n",
    "We will use *temperature* to determine how much we will obey the probability distribution returned by the neural network.\n",
    "A low temperature will only allow the most likely candidates and a high temperature will also consider more unlikely candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f6737-77e1-40bd-96fb-3c3fbfb463f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temp(preds, temp:float=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)/temp\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)\n",
    "\n",
    "def generate_text(seed_text: str, next_tokens: int, model: keras.Model, tokenizer: Tokenizer, max_sequence_len: int, temp: float, char_mode: bool = False):\n",
    "    output_text = seed_text\n",
    "    \n",
    "    for _ in range(next_tokens):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = token_list[-max_sequence_len:]\n",
    "        token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "        \n",
    "        probs = model.predict(token_list, verbose=0)[0]\n",
    "        y_class = sample_with_temp(probs, temp)\n",
    "        \n",
    "        output_token = tokenizer.index_word[y_class] if y_class > 0 else ''\n",
    "        \n",
    "        if char_mode:\n",
    "            seed_text += output_token\n",
    "            output_text += output_token\n",
    "        else:\n",
    "            seed_text += output_token + \" \"\n",
    "            output_text += output_token + \" \"\n",
    "        \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e238f01-9456-4e51-beb8-6ac20f4545fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K. fragte sich deigeischeinununischeischeischaunununischeischeischeischeischischischigeigeigeis\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\n",
    "    seed_text=\"K. fragte sich \",\n",
    "    next_tokens=80,\n",
    "    model=char_model,\n",
    "    max_sequence_len = 1,\n",
    "    tokenizer=char_tokenizer,\n",
    "    temp=0.2,\n",
    "    char_mode=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64cdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich gab ihm einen bissen brot und ließ es ihn essen. darüber ließe sich viel sagen. deischischeigeischeischigeischigeischaunischischeigeischeischeischeinischaununu\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\n",
    "    seed_text=\"Ich gab ihm einen Bissen Brot und ließ es ihn essen. Darüber ließe sich viel sagen.\".lower(),\n",
    "    next_tokens=80,\n",
    "    model=char_model,\n",
    "    max_sequence_len=1,\n",
    "    tokenizer=char_tokenizer,\n",
    "    temp=0.2,\n",
    "    char_mode=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49375556-37af-4639-9cbe-7327e230205d",
   "metadata": {},
   "source": [
    "## Model on word basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found words: 8675\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = Tokenizer(lower=True, char_level=False,)\n",
    "word_tokenizer.fit_on_texts([text])\n",
    "num_words = len(word_tokenizer.word_index)+1\n",
    "print(f\"Number of found words: {num_words}\")\n",
    "word_token_list = word_tokenizer.texts_to_sequences([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cb075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (454571, 40) \ty:  (454571, 8675)\n"
     ]
    }
   ],
   "source": [
    "X_word, y_word = generate_sequences(char_token_list, step=1, seq_length=40, num_classes=num_words)\n",
    "\n",
    "print(\"X: \", X_word.shape, \"\\ty: \", y_word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8d778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word_rnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 100)         867500    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               365568    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8675)              2229475   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,462,543\n",
      "Trainable params: 3,462,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_units = 256\n",
    "embedding_size = 100\n",
    "\n",
    "text_in = layers.Input(shape=(None,))\n",
    "x = layers.Embedding(num_words, embedding_size,)(text_in)\n",
    "x = layers.LSTM(n_units)(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "text_out = layers.Dense(num_words, activation='softmax')(x)\n",
    "\n",
    "word_model = Model(text_in, text_out, name=\"word_rnn\")\n",
    "\n",
    "word_model.compile(\n",
    "    # note that we use the same loss as with MNIST\n",
    "    # which is used when we want to learn a\n",
    "    # probability distribution\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=RMSprop(learning_rate=0.001)\n",
    ")\n",
    "\n",
    "word_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ad161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3552/3552 [==============================] - 462s 130ms/step - loss: 2.0518\n",
      "Epoch 2/5\n",
      "3552/3552 [==============================] - 403s 114ms/step - loss: 1.6040\n",
      "Epoch 3/5\n",
      "3552/3552 [==============================] - 420s 118ms/step - loss: 1.4644\n",
      "Epoch 4/5\n",
      "3552/3552 [==============================] - 422s 119ms/step - loss: 1.3898\n",
      "Epoch 5/5\n",
      "3552/3552 [==============================] - 442s 124ms/step - loss: 1.3432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16edb32b0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.fit(X_word, y_word, epochs=5, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k fragte sich und sich und sich aber eine so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\n",
    "    seed_text=\"k fragte sich \",\n",
    "    next_tokens=80,\n",
    "    model=word_model,\n",
    "    max_sequence_len = 1,\n",
    "    tokenizer=word_tokenizer,\n",
    "    temp=0.2,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75480084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
